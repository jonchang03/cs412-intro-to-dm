{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "The provided input file (\"categories.txt\") consists of the category lists of 77,185 places in the US. Each line corresponds to the category list of one place, where the list consists of a number of category instances (e.g., hotels, restaurants, etc.) that are separated by semicolons.\n",
    "\n",
    "An example line is provided below:\n",
    "\n",
    "Local Services;IT Services & Computer Repair\n",
    "\n",
    "In the example above, the corresponding place has two category instances: \"Local Services\" and \"IT Services & Computer Repair\".\n",
    "\n",
    "## Output\n",
    "You need to implement the Apriori algorithm and use it to mine category sets that are frequent in the input data. When implementing the Apriori algorithm, you may use any programming language you like. We only need your result pattern file, not your source code file.\n",
    "\n",
    "After implementing the Apriori algorithm, please set the relative minimum support to 0.01 and run it on the 77,185 category lists. In other words, you need to extract all the category sets that have an absolute support larger than 771."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "77185\n"
     ]
    }
   ],
   "source": [
    "# read \"categories.txt\" into list of lists\n",
    "# https://stackoverflow.com/questions/18448847/import-txt-file-and-having-each-line-as-a-list\n",
    "transactions = []\n",
    "with open('categories.txt', 'rt') as f:\n",
    "    for line in f:\n",
    "        transactions.append(line.strip().split(';'))\n",
    "print(type(transactions))\n",
    "print(len(transactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit**: http://adataanalyst.com/machine-learning/apriori-algorithm-python-3-0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createC1(Database):\n",
    "    \"\"\"Find frequent 1-itemsets from database of transactions\"\"\"\n",
    "    C1 = []\n",
    "    for transaction in Database:\n",
    "        for item in transaction:\n",
    "            if [item] not in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1)) # use frozenset so we can use it as a key in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scanD(D, Ck, min_sup):\n",
    "    \"\"\"\n",
    "    Given database, Ck (list of candidate sets), and min_support, \n",
    "    generate Lk from Ck and also return a dictionary with support values\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the support counts for all the transactions in candidate set, Ck\n",
    "    supCounts = dict() # dictionary with itemset (frozenset) as key, and counts as value\n",
    "    for tid in D:\n",
    "        for candidate in Ck:\n",
    "            if candidate.issubset(tid):\n",
    "                if candidate not in supCounts:\n",
    "                    supCounts[candidate] = 1\n",
    "                else:\n",
    "                    supCounts[candidate] += 1\n",
    "                    \n",
    "    # only add candidates to return list whose counts are greater than the minimum support\n",
    "    # recall key = itemset and value = support count    \n",
    "    retList = list()\n",
    "    supportData = dict()  \n",
    "    for key, value in supCounts.items():\n",
    "        # if value >= min_sup:\n",
    "        if value > min_sup:\n",
    "            retList.insert(0, key)\n",
    "            supportData[key] = value\n",
    "    return retList, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apriori Pseudo-code\n",
    "While the current frequent itemset is not empty:\n",
    "* generate a list of candidate itemsets of length k\n",
    "* scan the database to see if each itemset is frequent\n",
    "* keep frequent itemsets to create itemsets of length k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apriori_gen(Lk, k):\n",
    "    \"\"\"\n",
    "    Given list of frequent itemsets, Lk, and the size of the itemsets, k,\n",
    "    produce Ck, a list of candidate itemsets.\n",
    "    \"\"\"\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[:k-2]\n",
    "            L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort(); L2.sort() # for efficient implementation (pg 249 of book)\n",
    "            if (L1 == L2): # if first k-2 elements are equal\n",
    "                retList.append(Lk[i] | Lk[j]) # set union\n",
    "    return retList # BE CAREFUL OF TAB!        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apriori(database, min_sup = 771):\n",
    "    \"\"\"Main function for apriori algorithm\"\"\"\n",
    "    C1 = createC1(database)\n",
    "    D = list(map(set, database)) # becomes list of sets\n",
    "    L1, supportData = scanD(D, C1, min_sup)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0): # indexing off by 1\n",
    "        Ck = apriori_gen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, min_sup) # scan DB to get Lk\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Please output all the length-1 frequent categories with their absolute supports into a text file named \"patterns.txt\". Every line corresponds to exactly one frequent category and should be in the following format:\n",
    "\n",
    "support:category\n",
    "\n",
    "For example, suppose a category (Fast Food) has an absolute support 3000, then the line corresponding to this frequent category set in \"patterns.txt\" should be:\n",
    "\n",
    "3000:Fast Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 s, sys: 55.5 ms, total: 20.8 s\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_sup = 771\n",
    "C1 = createC1(transactions)\n",
    "L1, supData_part1 = scanD(transactions, C1, min_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'Nightlife'}): 5088,\n",
       " frozenset({'Home Services'}): 4785,\n",
       " frozenset({'Home & Garden'}): 1586,\n",
       " frozenset({'Pets'}): 1497,\n",
       " frozenset({'Pubs'}): 874,\n",
       " frozenset({'Shopping'}): 11233,\n",
       " frozenset({'Food'}): 9250,\n",
       " frozenset({'Bars'}): 4328,\n",
       " frozenset({'Nail Salons'}): 1667,\n",
       " frozenset({'Real Estate'}): 1424,\n",
       " frozenset({'Doctors'}): 1694,\n",
       " frozenset({'Hotels'}): 1431,\n",
       " frozenset({'Coffee & Tea'}): 2199,\n",
       " frozenset({'Burgers'}): 1774,\n",
       " frozenset({'Sandwiches'}): 2364,\n",
       " frozenset({'Local Services'}): 3468,\n",
       " frozenset({'Pet Services'}): 870,\n",
       " frozenset({'Restaurants'}): 25071,\n",
       " frozenset({'Japanese'}): 848,\n",
       " frozenset({'Health & Medical'}): 5121,\n",
       " frozenset({'Breakfast & Brunch'}): 1369,\n",
       " frozenset({'Professional Services'}): 1025,\n",
       " frozenset({'Hair Salons'}): 2091,\n",
       " frozenset({'Auto Repair'}): 1716,\n",
       " frozenset({'Mexican'}): 2515,\n",
       " frozenset({'General Dentistry'}): 823,\n",
       " frozenset({'Event Planning & Services'}): 2975,\n",
       " frozenset({\"Women's Clothing\"}): 1138,\n",
       " frozenset({'Chinese'}): 1629,\n",
       " frozenset({'Fast Food'}): 2851,\n",
       " frozenset({'Sports Bars'}): 818,\n",
       " frozenset({'Bakeries'}): 1115,\n",
       " frozenset({'Arts & Entertainment'}): 2271,\n",
       " frozenset({'Cafes'}): 1002,\n",
       " frozenset({'Automotive'}): 4208,\n",
       " frozenset({'Italian'}): 1848,\n",
       " frozenset({'Fashion'}): 3078,\n",
       " frozenset({'Fitness & Instruction'}): 1442,\n",
       " frozenset({'Dentists'}): 1195,\n",
       " frozenset({'Hotels & Travel'}): 2495,\n",
       " frozenset({'Specialty Food'}): 1150,\n",
       " frozenset({'Financial Services'}): 875,\n",
       " frozenset({'Sushi Bars'}): 798,\n",
       " frozenset({'Pizza'}): 2657,\n",
       " frozenset({'American (Traditional)'}): 2416,\n",
       " frozenset({'Grocery'}): 1424,\n",
       " frozenset({'American (New)'}): 1593,\n",
       " frozenset({'Ice Cream & Frozen Yogurt'}): 1018,\n",
       " frozenset({'Beauty & Spas'}): 6583,\n",
       " frozenset({'Active Life'}): 3103}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supData_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write results to  it to \"patterns.txt\"\n",
    "# https://stackoverflow.com/questions/17801665/how-to-get-an-arbitrary-element-from-a-frozenset/17844057#17844057\n",
    "with open('part1/part1_v2.txt', 'wt') as f:\n",
    "    for k, v in supData_part1.items():\n",
    "        x, = k\n",
    "        f.write(str(v) + ':' + str(x) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Please write all the frequent category sets along with their absolute supports into a text file named \"patterns.txt\". Every line corresponds to exactly one frequent category set and should be in the following format:\n",
    "\n",
    "support:category_1;category_2;category_3;...\n",
    "\n",
    "For example, suppose a category set (Fast Food; Restaurants) has an absolute support 2851, then the line corresponding to this frequent category set in \"patterns.txt\" should be:\n",
    "\n",
    "2851:Fast Food;Restaurants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 78.9 ms, total: 18.4 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "L, supData_part2 = apriori(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(supData_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# supData_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195:Dentists;Health & Medical\n",
      "\n",
      "1716:Automotive;Auto Repair\n",
      "\n",
      "1586:Home & Garden\n",
      "\n",
      "1774:Burgers\n",
      "\n",
      "1138:Shopping;Women's Clothing\n",
      "\n",
      "1431:Hotels & Travel;Hotels\n",
      "\n",
      "774:Burgers;Fast Food\n",
      "\n",
      "2423:Restaurants;Bars\n",
      "\n",
      "2091:Hair Salons\n",
      "\n",
      "848:Restaurants;Japanese\n",
      "\n",
      "9250:Food\n",
      "\n",
      "1667:Nail Salons\n",
      "\n",
      "1694:Doctors\n",
      "\n",
      "774:Restaurants;Burgers;Fast Food\n",
      "\n",
      "1424:Home Services;Real Estate\n",
      "\n",
      "2271:Arts & Entertainment\n",
      "\n",
      "2975:Event Planning & Services\n",
      "\n",
      "3468:Local Services\n",
      "\n",
      "2101:Food;Restaurants\n",
      "\n",
      "870:Pet Services\n",
      "\n",
      "25071:Restaurants\n",
      "\n",
      "5121:Health & Medical\n",
      "\n",
      "6583:Beauty & Spas\n",
      "\n",
      "818:Sports Bars;Nightlife\n",
      "\n",
      "823:General Dentistry;Dentists\n",
      "\n",
      "874:Bars;Pubs;Nightlife\n",
      "\n",
      "4328:Bars;Nightlife\n",
      "\n",
      "3078:Shopping;Fashion\n",
      "\n",
      "2515:Mexican\n",
      "\n",
      "823:General Dentistry\n",
      "\n",
      "823:General Dentistry;Dentists;Health & Medical\n",
      "\n",
      "1150:Specialty Food\n",
      "\n",
      "1848:Italian\n",
      "\n",
      "2515:Restaurants;Mexican\n",
      "\n",
      "823:General Dentistry;Health & Medical\n",
      "\n",
      "1115:Bakeries\n",
      "\n",
      "1369:Restaurants;Breakfast & Brunch\n",
      "\n",
      "1431:Event Planning & Services;Hotels\n",
      "\n",
      "1593:American (New);Restaurants\n",
      "\n",
      "1002:Cafes\n",
      "\n",
      "4208:Automotive\n",
      "\n",
      "2091:Hair Salons;Beauty & Spas\n",
      "\n",
      "3078:Fashion\n",
      "\n",
      "798:Restaurants;Sushi Bars\n",
      "\n",
      "1431:Event Planning & Services;Hotels & Travel;Hotels\n",
      "\n",
      "1694:Doctors;Health & Medical\n",
      "\n",
      "2495:Hotels & Travel\n",
      "\n",
      "2657:Pizza\n",
      "\n",
      "2416:American (Traditional)\n",
      "\n",
      "1138:Shopping;Women's Clothing;Fashion\n",
      "\n",
      "1424:Grocery\n",
      "\n",
      "1593:American (New)\n",
      "\n",
      "1774:Restaurants;Burgers\n",
      "\n",
      "5088:Nightlife\n",
      "\n",
      "4785:Home Services\n",
      "\n",
      "1497:Pets\n",
      "\n",
      "874:Pubs\n",
      "\n",
      "874:Pubs;Nightlife\n",
      "\n",
      "1018:Food;Ice Cream & Frozen Yogurt\n",
      "\n",
      "2657:Restaurants;Pizza\n",
      "\n",
      "4328:Bars\n",
      "\n",
      "1442:Fitness & Instruction;Active Life\n",
      "\n",
      "1424:Real Estate\n",
      "\n",
      "1431:Hotels\n",
      "\n",
      "2199:Coffee & Tea\n",
      "\n",
      "2364:Sandwiches\n",
      "\n",
      "2533:Restaurants;Nightlife\n",
      "\n",
      "1002:Cafes;Restaurants\n",
      "\n",
      "798:Sushi Bars\n",
      "\n",
      "874:Bars;Pubs\n",
      "\n",
      "1369:Breakfast & Brunch\n",
      "\n",
      "1025:Professional Services\n",
      "\n",
      "11233:Shopping\n",
      "\n",
      "1629:Restaurants;Chinese\n",
      "\n",
      "2199:Food;Coffee & Tea\n",
      "\n",
      "1716:Auto Repair\n",
      "\n",
      "1150:Food;Specialty Food\n",
      "\n",
      "1138:Women's Clothing\n",
      "\n",
      "1629:Chinese\n",
      "\n",
      "2851:Fast Food\n",
      "\n",
      "1848:Restaurants;Italian\n",
      "\n",
      "2423:Restaurants;Bars;Nightlife\n",
      "\n",
      "2364:Restaurants;Sandwiches\n",
      "\n",
      "1471:Event Planning & Services;Hotels & Travel\n",
      "\n",
      "818:Sports Bars\n",
      "\n",
      "870:Pet Services;Pets\n",
      "\n",
      "1586:Home & Garden;Shopping\n",
      "\n",
      "818:Bars;Sports Bars;Nightlife\n",
      "\n",
      "1667:Beauty & Spas;Nail Salons\n",
      "\n",
      "1424:Grocery;Food\n",
      "\n",
      "2851:Restaurants;Fast Food\n",
      "\n",
      "1442:Fitness & Instruction\n",
      "\n",
      "818:Bars;Sports Bars\n",
      "\n",
      "1195:Dentists\n",
      "\n",
      "1115:Bakeries;Food\n",
      "\n",
      "875:Financial Services\n",
      "\n",
      "848:Japanese\n",
      "\n",
      "1138:Fashion;Women's Clothing\n",
      "\n",
      "1018:Ice Cream & Frozen Yogurt\n",
      "\n",
      "2416:Restaurants;American (Traditional)\n",
      "\n",
      "3103:Active Life\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/2399112/python-print-delimited-list\n",
    "category_set = []\n",
    "for k, v in supData_part2.items():\n",
    "    # category_set = list(k)\n",
    "    category_set = [x for x in k]\n",
    "    print(str(v) + ':' + ';'.join(map(str, category_set)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_set = []\n",
    "with open('part2/v2/patterns_test.txt', 'wt') as f:\n",
    "    for k, v in supData_part2.items():\n",
    "        # category_set = list(k)\n",
    "        category_set = [x for x in k]\n",
    "        f.write(str(v) + ':' + ';'.join(map(str, category_set)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
